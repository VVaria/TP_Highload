# TP_Highload
Домашнее задание по курсу технопарка Highload

# Tumblr

# MVP
1. Авторизация/регистрация
2. Создание блога/постов
3. Просмотр ленты рекомендаций

# Целевая аудитория
* 320 млн посещений в месяц
* 7,2 млн новых блогов создаются ежемесячно
* приблизительно 9,7 млн. пользователей, посещающих платформу ежедневно
* 22 млн постов каждый день
* среднее время, проведенное на платформе 9 минут
* платформа используется по всему миру
  * 50% трафика - Северная Америка (в основном США)
  * 30% - Европа
  * 12% - Азия
  * 3% - Австралия

# Расчет нагрузки
### Продуктовые метрики
1. Месячная аудитория составляет около 320 млн. уникальных посещений
2. Дневная аудитория - 10,3 млн пользователей
3. Если взять общее количество аккаунтов 490 млн и всего опубликованных постов ~180 млрд, то получаем 
```
180000 / 480 = 367 постов на один блог (нужно учитывать, что есть блоги, которые постоянно публикуют посты и их там больше, а в некоторых может быть 10 постов)
```
Вес одного поста при загрузке изображения или gif достигает 3мб, видео - до 100мб. При хранении размер картинок ужимается до ~1Мб, gif до 0,8Мб, видео до 5Мб в среднем. Данные о хранимом размере были получены путем анализа загрузки страницы при скролле рекомендаций. На сайте подгружались картинки, гифки, видео. В разделе Network можно было посмотреть размер данных.
Большей частью постов являются изображения - ~85%, gif - ~10%, видео - ~5%. Данная информация была взята путем анализа статистики из источников, а также анализом загружаемых постов  в ленте рекомендаций. Сервис tumblr изначально был создан для того, чтобы делиться каринками в постах, именно они и занимают большую часть хранилища, gif были добавлены в 2018 году. Загрузка видео в посты не так велика, потому что на этом сервисе attention span к видео мал. 
```
(0.85 * 1 + 0.1 * 0,8 + 0.05 * 5) * 367 = 433Мб примерно хранилище одного пользователя
```
4. Среднее время просмотра ленты составляет 9 минут, если считать, что показывается по 4 поста в течение 5 секунд, то за 9 минут подгружается
```
4 * 9 * 60 / 5 = 432 поста  
```
При скролле страницы в течении 10 секунд отправляется 2000 запросов на одного пользователя (использовался WireShark)
```
10 млн * 2000 * 6 * 9 = 1 млрд запросов в день
```
5. Каждый день создается около 50Гб новых постов и 2.7Тб обновлений списков последователей
6. Ежемесячно 330 млн уникальных посещений, это пирблизительно 10 млн посещений в день из них около 5% авторизаций => примерно 500тыс запросов на авторизацию.
   Годовой прирост аудитории ~ 30 млн пользователей:
```
30 млн / 365 = 82 тыс запросов на регистрацию в день
```

### Технические метрики
1. Общее количество постов ~180 млрд, из них 85% - изображения, 10% - gif, 5% - видео.
```
0.85 * 180млрд * 1 / (1024 ^ 3) = 142,4Пб - изображения
0.1 * 180млрд * 0,8 / (1024 ^ 3) = 13,4Пб - gif
0.05 * 180млрд * 5 / (1024 ^ 3) = 41,9Пб - видео
480 млн * 10 / 1024 ^ 2 = 4,5 Тб - остальная информация (о пользователях, тексты и тд)
```
2. Сетевой трафик
  * При создании: 22 млн постов каждый день, средний размер поста еще не в сжатом состоянии 3Мб + верстка и отдача контента.
 ```
 22млн / (24 * 60 * 60) * 3 ~ 763 Мб/с 
 ```
  * При загрузке ленты: 110 млн запросов на выгрузку постов в день. В каждом запросе по 40 постов + отдача верстки, текста
  ```
  110млн * 40 / (24 * 60 * 60) * 40 / 1024 ~ 2100Мб/с - пиковая нагрузка
  ```
 3. RPS: 
 
 Запрос          |      RPS      | Доп. информация при расчетах       
 :-------------: | :-----------: | :--------------------------------: 
 Регистрации     | 1             | 82 тыс. запросов в день            
 Авторизации     | 5             | 500 тыс. запросов в день             
 Создание блога  | 3             | 7,2 млн созданий ежемесячно       
 Создание постов | 1440          | 1427 постов создается в секунду[2] 
 Просмотр ленты  | 23000         | 110 млн запросов в день, 10 млн посещений            


# Логическая схема
![image](https://user-images.githubusercontent.com/34479597/142927884-4e7cd008-2c45-4de3-bdc2-fe32509f3a20.png)

# Физическая схема
Базы пользователей, постов и блога будут храниться в реляционной СУБД MySQL. В данном случае это является наиболее простым и выгодным решением. Также будет настроены шардинг и репликация для снижения нагрузки на взаимодействие с данными и поддержания отказоустойчивости. Для чтения будем использовать как раз реплики.  Внутренним сервисам необходим доступ к потоку всех событий в системе (создание, редактирование и удаление постов), для чего можно создать внутреннюю шину сообщений c использованием Kafka. Это разгрузит поток запросов, который достаточно большой и запросы будут браться в порядке очереди. Для Users.id, Posts.id, Posts.user делаем hash-индексацию для быстрого поиска и сравнения.

Таблица хэштегов представляет с собой k-value данные, поэтому для нее удобно будет использовать NoSQL.

Сессии пользователя очень удобно хранить в нереляционной бд, потому что также представляют собой key-value, и поскольку к данным нужен быстрый доступ, можно вопсользоваться Redis.

Для периодического сохранения текущей позиции каждого клиента в потоке будем использовать ZooKeeper. Таким образом будет поддерживаться актуальность постов для пользователя, его состояние в ленте рекомендаций. Для постов будет настроено кэширование, где копии постов можно достать по идентификаторам, что позволяет выдать все данные для отрисовки без обращений к серверам. Воспользуемся в этом случае Redis.

Также важно учесть, что нам необходимо хранить метаданные постов, то есть фотографии, гиф, видео или музыку. Для этого можно воспользоваться облачным хранилищем MCS. Оно отлично подойдет благодаря высокой степени надежности хранения, а также данное хранилище обеспечит высокую скорость трафика в 1Gb/s.

# Технологии
### Фронтенд
Для написание будут использоваться современные, наиболее популярные технологии: HTML, SCSS, TypeScript. Выбираем TypeScript, потому что он обладает большими возможностями, чем JS, а также является более производительным и эффективным. Но не отменяем возможности использования JS. Основываясь на структуре приложения можно выбрать библиотеку React для написания компонентов. Поскольку библиотека React известна как мощное средство для создания динамических и интерактивных пользовательских интерфейсов. Сборка будет осуществляться с помощью webpack. 

### Backend
Для большого приложения с разнообразными возможностями лучше всего использовать микросервисную архитектуру, потому что это позволит легче масштабироваться и распределять равномерно нагрузку на сервисы. Основным языком будет Go, поскольку он является производительным, поддерживает параллелизм, может выдерживать хорошую нагрузку. (Основываясь на личном опыте из курса БД) Благодаря микросервисной архитектуре поддерживается удобное написание отдельных микросервисов на других языках программирования.  Микросервис рекомендаций можно реализовать с помощью искуственного интеллекта, написанного на Python. Общение между микросервисами будет происходить по gRPC.

### Mobile
Приложение tumblr пользуется такой же популярностью, как и веб-версия. Для реализации мобильного приложения можно просто использовать наиболее популярные и часто применяемые языки программирования. Для Android можно использовать Kotlin, для IOS - Swift.

# Схема проекта
![image](https://user-images.githubusercontent.com/34479597/145714184-39397337-a710-43d7-8fd0-753c5dbcedd8.png)

# Список серверов
Tumblr используется всемирно, поэтому дата-центры должны  располагаться также на разных материках для обеспечения быстрого доступа пользователей, находящихся в разных точках мира. В настоящий момент у tumblr насчитывается около 1000 серверов. Наиболее популярен tumblr в Америке и Европе, поэтому основные базы нужно располагать в США - в центре материка Северная Америка и в Европе - также в центре, например в Германии. Азия и Россия пользуются гораздо меньшей популярностью, поэтоме можно расположить дата центр где-нибудь в центре Азии.
В каждом дата центре будут находится как основные хранилища, так и резервы.
Соответсвенно, нужно рассчитать конфигурации и число серверов для:
* frontend
* backend
* сервера СУБД MySQL
* сервера СУБД Redis
* балансировщика
* сервера очередей задач

*Frontend*

Любое веб-приложение требует быстрой отдачи фронта. Оптимизируя код будем стараться добиться из 5Мб -> 300 Kб. Пусть, возьмем с запасом бандл будет ~ 500Kб, тогда зная среднее число пользователей в день - 9 700 000, а значит в среднем в час 404 160, значит в худшем случае в час гоняется 202 083 Мб данных. Получается, ~ 4Гб/мин, => 70Mb/s. 1 SSD имеет скорость чтения/записи: 250MB/s Значит поставим на 1 фронтенд сервер 1 SSD на 512 МБ.
   CPU (ядер)    |    RAM (ГБ)   | 	SSD (Мб)    |  Количество
 :-------------: | :-----------: | :-----------:| :----------------:
       32        |   64          |     512      |    4 + 4 (резерв)  

*Backend*

Для бекенда go в сочетании с СУБД на запись может выдавать до 2000rps с 2-х ядерным процессором и 8Гб ОЗУ. Соответсвенно для записи будет достаточно шардинга. Но нужно учесть еще чтение - с такими же комплектующими на чтение может выдавать до 2000rps, а если увеличить количество ядер до 4, то в два раза больше. Соответсвенно можно добавить ядер и ОЗУ для того, чтобы поднять возможности одной машины до 50000rps
   CPU (ядер)    |    RAM (ГБ)   | 	SSD (Мб)    |  Количество
 :-------------: | :-----------: | :-----------:| :------------------:
       64        |   128         |     128      |    10 + 10 (резерв)  

*СУБД MySQL*

Для поддержания стабильной и быстрой работы баз данных увеличим RAM и CPU. У нас три базы данных: пользователи, посты, блоги. Всего пользователей сервиса около 430 млн, а постов около 180 млрд, с каждым месяцом количество данных растет и создается до 7 млн новых блогов, тогда с учетом этого получаем: 
   CPU (ядер)    |    RAM (ГБ)   | 	SSD (Мб)    |  Количество
 :-------------: | :-----------: | :-----------:| :-------------------:
       64        |   128         |     128      |    100 + 100 (резерв)  
100 баз в трех ДЦ -> 33 бд в одном 

*СУБД Redis*

Здесь главное рассчитать нужное число ОЗУ для данной СУБД, так как один пост ~ 3000 байт запись, а в месяц всего хранится около 300 млн постов (учитывая среднюю месячную отдачу в 700 млн постов и то, что у нас сервера будут находится в трех разных точках), желательно хранить хотя бы 2 месяца для рекомендаций, тогда получается ~ 3000 * 300 ~ 900 Гб ОЗУ/месяц, тогда берем в одну БД 1,5Тб ОЗУ. Реплика сервера будет аналогична мастеру.
   CPU (ядер)    |    RAM (ГБ)   | 	HDD (ТБ)    |  Количество
 :-------------: | :-----------: | :-----------:| :----------:
        16       |   1500        |    -         |    6 + 6  



# Используемые источники
1. https://onlypult.com/ru/blog/gid-po-rabote-v-tumblr-dlya-nachinauschih
2. https://saasscout.com/statistics/tumblr-statistics/
3. https://www.statista.com/topics/2463/tumblr/
4. https://www.insight-it.ru/highload/2012/arkhitektura-tumblr/
